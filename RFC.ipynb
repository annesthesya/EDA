{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install emoji\n",
    "# !pip install num2words\n",
    "# !pip install nltk\n",
    "# !pip install matplotlib\n",
    "# !pip install wordcloud\n",
    "# !pip install ipynb \n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tiast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tiast\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import emoji\n",
    "from num2words import num2words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from matplotlib import colors\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.preprocessor_class import Preprocessor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:09.171458400Z",
     "start_time": "2024-01-02T22:13:09.009846600Z"
    }
   },
   "id": "87f5ca3ef597188b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(45000, 1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/shuffled_train_data.csv',index_col=None)\n",
    "train_labels = pd.read_csv('data/shuffled_train_labels.csv',index_col=None)\n",
    "\n",
    "test_data = pd.read_csv('data/test_data.csv',index_col=None)\n",
    "test_labels = pd.read_csv('data/test_labels.csv',index_col=None)\n",
    "\n",
    "train_data_plot = pd.read_csv('data/train_data_plot.csv',index_col=None)\n",
    "test_data_plot = pd.read_csv('data/test_data_plot.csv',index_col=None)\n",
    "\n",
    "train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:11.861475500Z",
     "start_time": "2024-01-02T22:13:11.541540700Z"
    }
   },
   "id": "cb81101d938564cd"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(set(stopwords.words('english')), WordNetLemmatizer(), PorterStemmer(), True, True, True, True, True, False, True, True, True, False)\n",
    "\n",
    "preprocessed_data = pd.DataFrame(columns=['text'])\n",
    "\n",
    "preprocessed_data_train = pd.DataFrame(columns=['text'])\n",
    "preprocessed_data_test = pd.DataFrame(columns=['text'])\n",
    "\n",
    "preprocessed_data_train['text'] = train_data.apply(lambda row: preprocessor.preprocess(row.iloc[0]), axis = 1)\n",
    "\n",
    "preprocessed_data_test['text'] = test_data.apply(lambda row: preprocessor.preprocess(row.iloc[0]), axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.254333300Z",
     "start_time": "2024-01-02T22:13:13.389299900Z"
    }
   },
   "id": "ed53dddf94acc37f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text\n0                           poorly made shrink fit well\n1     playing santa year authentic high quality sant...\n2     bought two one better shipping schedule second...\n3     came box scratch one lense know inexpensive un...\n4     okay kind hard explain really liked skirt know...\n...                                                 ...\n5995  christmas gift boyfriend nice wallet appears l...\n5996               better expected pleasantly surprised\n5997  skirt awsome arrived real quick lb skirt fit l...\n5998  excellent piece elegant sturdy design love fac...\n5999                              wonderful beach shirt\n\n[6000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>poorly made shrink fit well</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>playing santa year authentic high quality sant...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bought two one better shipping schedule second...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>came box scratch one lense know inexpensive un...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>okay kind hard explain really liked skirt know...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5995</th>\n      <td>christmas gift boyfriend nice wallet appears l...</td>\n    </tr>\n    <tr>\n      <th>5996</th>\n      <td>better expected pleasantly surprised</td>\n    </tr>\n    <tr>\n      <th>5997</th>\n      <td>skirt awsome arrived real quick lb skirt fit l...</td>\n    </tr>\n    <tr>\n      <th>5998</th>\n      <td>excellent piece elegant sturdy design love fac...</td>\n    </tr>\n    <tr>\n      <th>5999</th>\n      <td>wonderful beach shirt</td>\n    </tr>\n  </tbody>\n</table>\n<p>6000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_test['text'] = preprocessed_data_test['text'].apply(lambda x: ' '.join(map(str, x)))\n",
    "preprocessed_data_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.303530200Z",
     "start_time": "2024-01-02T22:13:19.256919100Z"
    }
   },
   "id": "69a6fbba2d138cbd"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text\n0                                 love super comfortable\n1      shave cremes need lather feeling fullness rich...\n2      love bright color dress fabric nice feel reall...\n3                  see small got curve get fit like size\n4            sister love wolf go wrong cute comfy wolfie\n...                                                  ...\n44995  sandal poorly constructed base shoe fitting ex...\n44996  wow shirt comfortable fit hug body softness fr...\n44997  problem heel pain pf looking good walking shoe...\n44998  keep spotting hand everything blue ink even le...\n44999                 light died right away poor quality\n\n[45000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>love super comfortable</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>shave cremes need lather feeling fullness rich...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>love bright color dress fabric nice feel reall...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>see small got curve get fit like size</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sister love wolf go wrong cute comfy wolfie</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44995</th>\n      <td>sandal poorly constructed base shoe fitting ex...</td>\n    </tr>\n    <tr>\n      <th>44996</th>\n      <td>wow shirt comfortable fit hug body softness fr...</td>\n    </tr>\n    <tr>\n      <th>44997</th>\n      <td>problem heel pain pf looking good walking shoe...</td>\n    </tr>\n    <tr>\n      <th>44998</th>\n      <td>keep spotting hand everything blue ink even le...</td>\n    </tr>\n    <tr>\n      <th>44999</th>\n      <td>light died right away poor quality</td>\n    </tr>\n  </tbody>\n</table>\n<p>45000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_train['text'] = preprocessed_data_train['text'].apply(lambda x: ' '.join(map(str, x)))\n",
    "preprocessed_data_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.428872300Z",
     "start_time": "2024-01-02T22:13:19.287880500Z"
    }
   },
   "id": "f5391004656850b6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.77      0.69      2250\n",
      "     neutral       0.45      0.27      0.34      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6391666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.26      0.34      1500\n",
      "    positive       0.74      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6546666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.51      0.25      0.33      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6696666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.76      0.69      2250\n",
      "     neutral       0.44      0.27      0.33      1500\n",
      "    positive       0.72      0.75      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.59      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6351666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.46      0.25      0.33      1500\n",
      "    positive       0.74      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6545\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.23      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6653333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.44      0.26      0.32      1500\n",
      "    positive       0.73      0.76      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6421666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.25      0.33      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.655\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.33      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6695\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.43      0.27      0.34      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6406666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.47      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6508333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.51      0.25      0.34      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6703333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.75      0.68      2250\n",
      "     neutral       0.43      0.27      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.59      0.59      0.59      6000\n",
      "weighted avg       0.61      0.63      0.62      6000\n",
      "\n",
      "accuracy: 0.6336666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6525\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6673333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.76      0.69      2250\n",
      "     neutral       0.41      0.26      0.32      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.59      0.59      0.59      6000\n",
      "weighted avg       0.61      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6355\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.61      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.659\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.50      0.24      0.33      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6681666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.76      0.70      2250\n",
      "     neutral       0.43      0.27      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6396666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.47      0.26      0.34      1500\n",
      "    positive       0.72      0.79      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.654\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.51      0.26      0.35      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.65      6000\n",
      "\n",
      "accuracy: 0.6698333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.44      0.26      0.33      1500\n",
      "    positive       0.72      0.75      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.639\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.61      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.6586666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.50      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6658333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.45      0.28      0.34      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6491666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.46      0.25      0.32      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6555\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6655\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.42      0.24      0.31      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.59      0.59      0.58      6000\n",
      "weighted avg       0.61      0.64      0.61      6000\n",
      "\n",
      "accuracy: 0.6361666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.71      2250\n",
      "     neutral       0.48      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6558333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.22      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6695\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.78      0.69      2250\n",
      "     neutral       0.47      0.26      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6401666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.47      0.24      0.31      1500\n",
      "    positive       0.72      0.79      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.59      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6531666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.669\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.45      0.24      0.31      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.641\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6683333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.644\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.51      0.26      0.35      1500\n",
      "    positive       0.74      0.80      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.666\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.54      0.24      0.33      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.65      6000\n",
      "\n",
      "accuracy: 0.6765\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.28      0.35      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6523333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.663\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.21      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.6668333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6505\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.74      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.658\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.82      0.73      2250\n",
      "     neutral       0.52      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6721666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.45      0.26      0.33      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6435\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.48      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6568333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.55      0.23      0.32      1500\n",
      "    positive       0.72      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.64      6000\n",
      "\n",
      "accuracy: 0.6753333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.27      0.34      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6491666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.47      0.24      0.32      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6553333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.53      0.22      0.31      1500\n",
      "    positive       0.73      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6745\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.25      0.33      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6443333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6606666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6715\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.69      2250\n",
      "     neutral       0.47      0.26      0.34      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6406666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.46      0.22      0.30      1500\n",
      "    positive       0.72      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6486666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.54      0.22      0.32      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6736666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.76      0.68      2250\n",
      "     neutral       0.44      0.25      0.32      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.59      0.59      0.58      6000\n",
      "weighted avg       0.61      0.63      0.61      6000\n",
      "\n",
      "accuracy: 0.6335\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.22      0.31      1500\n",
      "    positive       0.72      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6555\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.83      0.72      2250\n",
      "     neutral       0.52      0.20      0.29      1500\n",
      "    positive       0.74      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6726666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.69      2250\n",
      "     neutral       0.45      0.24      0.32      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.59      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6378333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6506666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.51      0.20      0.29      1500\n",
      "    positive       0.73      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.59      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.6675\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.47      0.25      0.32      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6476666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.50      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6593333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.21      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.668\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.43      0.23      0.30      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6413333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.33      1500\n",
      "    positive       0.74      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6663333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.82      0.73      2250\n",
      "     neutral       0.55      0.22      0.31      1500\n",
      "    positive       0.73      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.64      6000\n",
      "\n",
      "accuracy: 0.6758333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.69      2250\n",
      "     neutral       0.45      0.24      0.31      1500\n",
      "    positive       0.72      0.77      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6403333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.49      0.23      0.31      1500\n",
      "    positive       0.74      0.80      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.73      2250\n",
      "     neutral       0.53      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6726666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.44      0.25      0.32      1500\n",
      "    positive       0.72      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6463333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.50      0.25      0.33      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.6608333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.73      2250\n",
      "     neutral       0.54      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6738333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.47      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6498333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.48      0.22      0.31      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.53      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6728333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.47      0.25      0.32      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6451666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.23      0.31      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6613333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.53      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6698333333333333\n",
      "\n",
      "BEST SCORE\n",
      "TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "accuracy: 0.6765\n"
     ]
    }
   ],
   "source": [
    "vocab = 0\n",
    "# best_vocab = 0\n",
    "ij = 0\n",
    "# best_ij = 0\n",
    "# best_kernel = 0\n",
    "# best_gamma = 0\n",
    "# best_c = 0\n",
    "max_accuracy = 0\n",
    "best_model = 0\n",
    "best_tfidf = 0\n",
    "\n",
    "for vocab in [1000, 3000, 5000]:\n",
    "    for ij in range(1,4):\n",
    "        for criterion in ['gini', 'entropy', 'log_loss']:\n",
    "            for estimator in [10, 20, 100]:\n",
    "                    tfidf_vectorizer = TfidfVectorizer(max_features=vocab, ngram_range=(1,ij))\n",
    "                    train_tfidf = tfidf_vectorizer.fit_transform(preprocessed_data_train['text']) \n",
    "                    test_tfidf = tfidf_vectorizer.transform(preprocessed_data_test['text']) \n",
    "                    \n",
    "                    model = RandomForestClassifier(n_estimators = estimator, criterion=criterion)\n",
    "                    \n",
    "                    print(\"\\n\", tfidf_vectorizer)\n",
    "                    print(model)\n",
    "                    \n",
    "                    model.fit(train_tfidf, train_labels['label'])\n",
    "                    predictii = model.predict(test_tfidf)\n",
    "                    accuracy = metrics.accuracy_score(test_labels['label'], predictii)\n",
    "                    \n",
    "                    if accuracy > max_accuracy:\n",
    "                        best_model = model\n",
    "                        best_tfidf = tfidf_vectorizer\n",
    "                        # best_vocab = vocab\n",
    "                        # best_ij = ij\n",
    "                        # best_kernel = kernel\n",
    "                        # best_gamma = gamma\n",
    "                        # best_c = c\n",
    "                        max_accuracy = accuracy\n",
    "                        \n",
    "                    print(classification_report(test_labels['label'], predictii))\n",
    "                    print(\"accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\nBEST SCORE\")\n",
    "print(best_tfidf)\n",
    "print(best_model)\n",
    "# print(classification_report(test_labels['label'], predictii))\n",
    "print(\"accuracy:\", max_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:53:17.712165700Z",
     "start_time": "2023-12-28T12:00:03.596175600Z"
    }
   },
   "id": "b6758b23bd88342c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1,2))\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(preprocessed_data_train['text']) \n",
    "test_tfidf = tfidf_vectorizer.transform(preprocessed_data_test['text']) \n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(train_tfidf, train_labels['label'])\n",
    "predictii = model.predict(test_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:16:28.134111100Z",
     "start_time": "2024-01-02T22:13:22.451333Z"
    }
   },
   "id": "eefabf7012fbb6b0"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels['label'], predictii)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:16:53.644177700Z",
     "start_time": "2024-01-02T22:16:52.943196300Z"
    }
   },
   "id": "88167700689cc17a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
