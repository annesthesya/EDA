{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install emoji\n",
    "# !pip install num2words\n",
    "# !pip install nltk\n",
    "# !pip install matplotlib\n",
    "# !pip install wordcloud\n",
    "# !pip install ipynb \n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f5ca3ef597188b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:09.171458400Z",
     "start_time": "2024-01-02T22:13:09.009846600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andreea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andreea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andreea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andreea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import emoji\n",
    "from num2words import num2words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from matplotlib import colors\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.preprocessor_class import Preprocessor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb81101d938564cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:11.861475500Z",
     "start_time": "2024-01-02T22:13:11.541540700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/shuffled_train_data.csv',index_col=None)\n",
    "train_labels = pd.read_csv('data/shuffled_train_labels.csv',index_col=None)\n",
    "\n",
    "test_data = pd.read_csv('data/test_data.csv',index_col=None)\n",
    "test_labels = pd.read_csv('data/test_labels.csv',index_col=None)\n",
    "\n",
    "train_data_plot = pd.read_csv('data/train_data_plot.csv',index_col=None)\n",
    "test_data_plot = pd.read_csv('data/test_data_plot.csv',index_col=None)\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed53dddf94acc37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.254333300Z",
     "start_time": "2024-01-02T22:13:13.389299900Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(set(stopwords.words('english')), WordNetLemmatizer(), PorterStemmer(), True, True, True, True, True, False, True, True, True, False)\n",
    "\n",
    "preprocessed_data = pd.DataFrame(columns=['text'])\n",
    "\n",
    "preprocessed_data_train = pd.DataFrame(columns=['text'])\n",
    "preprocessed_data_test = pd.DataFrame(columns=['text'])\n",
    "\n",
    "preprocessed_data_train['text'] = train_data.apply(lambda row: preprocessor.preprocess(row.iloc[0]), axis = 1)\n",
    "\n",
    "preprocessed_data_test['text'] = test_data.apply(lambda row: preprocessor.preprocess(row.iloc[0]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a6fbba2d138cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.303530200Z",
     "start_time": "2024-01-02T22:13:19.256919100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poorly made shrink fit well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playing santa year authentic high quality sant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought two one better shipping schedule second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>came box scratch one lense know inexpensive un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay kind hard explain really liked skirt know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>christmas gift boyfriend nice wallet appears l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>better expected pleasantly surprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>skirt awsome arrived real quick lb skirt fit l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>excellent piece elegant sturdy design love fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>wonderful beach shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                           poorly made shrink fit well\n",
       "1     playing santa year authentic high quality sant...\n",
       "2     bought two one better shipping schedule second...\n",
       "3     came box scratch one lense know inexpensive un...\n",
       "4     okay kind hard explain really liked skirt know...\n",
       "...                                                 ...\n",
       "5995  christmas gift boyfriend nice wallet appears l...\n",
       "5996               better expected pleasantly surprised\n",
       "5997  skirt awsome arrived real quick lb skirt fit l...\n",
       "5998  excellent piece elegant sturdy design love fac...\n",
       "5999                              wonderful beach shirt\n",
       "\n",
       "[6000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_test['text'] = preprocessed_data_test['text'].apply(lambda x: ' '.join(map(str, x)))\n",
    "preprocessed_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5391004656850b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:13:19.428872300Z",
     "start_time": "2024-01-02T22:13:19.287880500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love super comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shave cremes need lather feeling fullness rich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love bright color dress fabric nice feel reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see small got curve get fit like size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sister love wolf go wrong cute comfy wolfie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>sandal poorly constructed base shoe fitting ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>wow shirt comfortable fit hug body softness fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>problem heel pain pf looking good walking shoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>keep spotting hand everything blue ink even le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>light died right away poor quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                 love super comfortable\n",
       "1      shave cremes need lather feeling fullness rich...\n",
       "2      love bright color dress fabric nice feel reall...\n",
       "3                  see small got curve get fit like size\n",
       "4            sister love wolf go wrong cute comfy wolfie\n",
       "...                                                  ...\n",
       "44995  sandal poorly constructed base shoe fitting ex...\n",
       "44996  wow shirt comfortable fit hug body softness fr...\n",
       "44997  problem heel pain pf looking good walking shoe...\n",
       "44998  keep spotting hand everything blue ink even le...\n",
       "44999                 light died right away poor quality\n",
       "\n",
       "[45000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_train['text'] = preprocessed_data_train['text'].apply(lambda x: ' '.join(map(str, x)))\n",
    "preprocessed_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6758b23bd88342c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T13:53:17.712165700Z",
     "start_time": "2023-12-28T12:00:03.596175600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.77      0.69      2250\n",
      "     neutral       0.45      0.27      0.34      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6391666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.26      0.34      1500\n",
      "    positive       0.74      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6546666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.51      0.25      0.33      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6696666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.76      0.69      2250\n",
      "     neutral       0.44      0.27      0.33      1500\n",
      "    positive       0.72      0.75      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.59      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6351666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.46      0.25      0.33      1500\n",
      "    positive       0.74      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6545\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.23      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6653333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.44      0.26      0.32      1500\n",
      "    positive       0.73      0.76      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6421666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.25      0.33      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.655\n",
      "\n",
      " TfidfVectorizer(max_features=1000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.33      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6695\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.43      0.27      0.34      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6406666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.47      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6508333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.51      0.25      0.34      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6703333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.75      0.68      2250\n",
      "     neutral       0.43      0.27      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.59      0.59      0.59      6000\n",
      "weighted avg       0.61      0.63      0.62      6000\n",
      "\n",
      "accuracy: 0.6336666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6525\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6673333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.76      0.69      2250\n",
      "     neutral       0.41      0.26      0.32      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.59      0.59      0.59      6000\n",
      "weighted avg       0.61      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6355\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.61      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.659\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.50      0.24      0.33      1500\n",
      "    positive       0.73      0.82      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6681666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.76      0.70      2250\n",
      "     neutral       0.43      0.27      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6396666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.47      0.26      0.34      1500\n",
      "    positive       0.72      0.79      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.654\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.51      0.26      0.35      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.65      6000\n",
      "\n",
      "accuracy: 0.6698333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.44      0.26      0.33      1500\n",
      "    positive       0.72      0.75      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.639\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.61      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.6586666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.50      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6658333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.45      0.28      0.34      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6491666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.46      0.25      0.32      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6555\n",
      "\n",
      " TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6655\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.42      0.24      0.31      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.59      0.59      0.58      6000\n",
      "weighted avg       0.61      0.64      0.61      6000\n",
      "\n",
      "accuracy: 0.6361666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.71      2250\n",
      "     neutral       0.48      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6558333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.22      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6695\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.78      0.69      2250\n",
      "     neutral       0.47      0.26      0.33      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6401666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.47      0.24      0.31      1500\n",
      "    positive       0.72      0.79      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.59      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6531666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.669\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.45      0.24      0.31      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.641\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6683333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.48      0.27      0.35      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.644\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.51      0.26      0.35      1500\n",
      "    positive       0.74      0.80      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.666\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.54      0.24      0.33      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.65      6000\n",
      "\n",
      "accuracy: 0.6765\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.28      0.35      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6523333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.663\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.21      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.6668333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.48      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6505\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.74      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.658\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.82      0.73      2250\n",
      "     neutral       0.52      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6721666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.45      0.26      0.33      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6435\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.79      0.71      2250\n",
      "     neutral       0.48      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6568333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.55      0.23      0.32      1500\n",
      "    positive       0.72      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.64      6000\n",
      "\n",
      "accuracy: 0.6753333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.27      0.34      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6491666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.47      0.24      0.32      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6553333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.81      0.73      2250\n",
      "     neutral       0.53      0.22      0.31      1500\n",
      "    positive       0.73      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6745\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.70      2250\n",
      "     neutral       0.46      0.25      0.33      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6443333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.24      0.32      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6606666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=3000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.52      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6715\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.69      2250\n",
      "     neutral       0.47      0.26      0.34      1500\n",
      "    positive       0.73      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6406666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.46      0.22      0.30      1500\n",
      "    positive       0.72      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6486666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.54      0.22      0.32      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6736666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.76      0.68      2250\n",
      "     neutral       0.44      0.25      0.32      1500\n",
      "    positive       0.72      0.76      0.74      2250\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.59      0.59      0.58      6000\n",
      "weighted avg       0.61      0.63      0.61      6000\n",
      "\n",
      "accuracy: 0.6335\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.22      0.31      1500\n",
      "    positive       0.72      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6555\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.83      0.72      2250\n",
      "     neutral       0.52      0.20      0.29      1500\n",
      "    positive       0.74      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6726666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.77      0.69      2250\n",
      "     neutral       0.45      0.24      0.32      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.59      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6378333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.47      0.23      0.31      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6506666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000)\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.51      0.20      0.29      1500\n",
      "    positive       0.73      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.59      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.6675\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.47      0.25      0.32      1500\n",
      "    positive       0.73      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.63      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6476666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.79      0.71      2250\n",
      "     neutral       0.50      0.25      0.33      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6593333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.21      0.30      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.64      0.67      0.63      6000\n",
      "\n",
      "accuracy: 0.668\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.43      0.23      0.30      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6413333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72      2250\n",
      "     neutral       0.51      0.24      0.33      1500\n",
      "    positive       0.74      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6663333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.82      0.73      2250\n",
      "     neutral       0.55      0.22      0.31      1500\n",
      "    positive       0.73      0.84      0.78      2250\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.64      0.63      0.61      6000\n",
      "weighted avg       0.66      0.68      0.64      6000\n",
      "\n",
      "accuracy: 0.6758333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.69      2250\n",
      "     neutral       0.45      0.24      0.31      1500\n",
      "    positive       0.72      0.77      0.74      2250\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.60      0.60      0.58      6000\n",
      "weighted avg       0.62      0.64      0.62      6000\n",
      "\n",
      "accuracy: 0.6403333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.79      0.70      2250\n",
      "     neutral       0.49      0.23      0.31      1500\n",
      "    positive       0.74      0.80      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.73      2250\n",
      "     neutral       0.53      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6726666666666666\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.78      0.71      2250\n",
      "     neutral       0.44      0.25      0.32      1500\n",
      "    positive       0.72      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.60      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6463333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.80      0.72      2250\n",
      "     neutral       0.50      0.25      0.33      1500\n",
      "    positive       0.73      0.79      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.62      0.60      6000\n",
      "weighted avg       0.64      0.66      0.64      6000\n",
      "\n",
      "accuracy: 0.6608333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.73      2250\n",
      "     neutral       0.54      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6738333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.77      0.70      2250\n",
      "     neutral       0.47      0.27      0.34      1500\n",
      "    positive       0.73      0.78      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.61      0.60      6000\n",
      "weighted avg       0.63      0.65      0.63      6000\n",
      "\n",
      "accuracy: 0.6498333333333334\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.48      0.22      0.31      1500\n",
      "    positive       0.73      0.80      0.76      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.59      6000\n",
      "weighted avg       0.63      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6561666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='entropy')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.53      0.22      0.31      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6728333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.78      0.70      2250\n",
      "     neutral       0.47      0.25      0.32      1500\n",
      "    positive       0.72      0.77      0.75      2250\n",
      "\n",
      "    accuracy                           0.65      6000\n",
      "   macro avg       0.61      0.60      0.59      6000\n",
      "weighted avg       0.62      0.65      0.62      6000\n",
      "\n",
      "accuracy: 0.6451666666666667\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss', n_estimators=20)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.80      0.71      2250\n",
      "     neutral       0.49      0.23      0.31      1500\n",
      "    positive       0.73      0.81      0.77      2250\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.62      0.61      0.60      6000\n",
      "weighted avg       0.64      0.66      0.63      6000\n",
      "\n",
      "accuracy: 0.6613333333333333\n",
      "\n",
      " TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
      "RandomForestClassifier(criterion='log_loss')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.82      0.72      2250\n",
      "     neutral       0.53      0.21      0.30      1500\n",
      "    positive       0.73      0.83      0.78      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.60      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n",
      "accuracy: 0.6698333333333333\n",
      "\n",
      "BEST SCORE\n",
      "TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
      "RandomForestClassifier()\n",
      "accuracy: 0.6765\n"
     ]
    }
   ],
   "source": [
    "vocab = 0\n",
    "# best_vocab = 0\n",
    "ij = 0\n",
    "# best_ij = 0\n",
    "# best_kernel = 0\n",
    "# best_gamma = 0\n",
    "# best_c = 0\n",
    "max_accuracy = 0\n",
    "best_model = 0\n",
    "best_tfidf = 0\n",
    "\n",
    "for vocab in [1000, 3000, 5000]:\n",
    "    for ij in range(1,4):\n",
    "        for criterion in ['gini', 'entropy', 'log_loss']:\n",
    "            for estimator in [10, 20, 100]:\n",
    "                    tfidf_vectorizer = TfidfVectorizer(max_features=vocab, ngram_range=(1,ij))\n",
    "                    train_tfidf = tfidf_vectorizer.fit_transform(preprocessed_data_train['text']) \n",
    "                    test_tfidf = tfidf_vectorizer.transform(preprocessed_data_test['text']) \n",
    "                    \n",
    "                    model = RandomForestClassifier(n_estimators = estimator, criterion=criterion)\n",
    "                    \n",
    "                    print(\"\\n\", tfidf_vectorizer)\n",
    "                    print(model)\n",
    "                    \n",
    "                    model.fit(train_tfidf, train_labels['label'])\n",
    "                    predictii = model.predict(test_tfidf)\n",
    "                    accuracy = metrics.accuracy_score(test_labels['label'], predictii)\n",
    "                    \n",
    "                    if accuracy > max_accuracy:\n",
    "                        best_model = model\n",
    "                        best_tfidf = tfidf_vectorizer\n",
    "                        # best_vocab = vocab\n",
    "                        # best_ij = ij\n",
    "                        # best_kernel = kernel\n",
    "                        # best_gamma = gamma\n",
    "                        # best_c = c\n",
    "                        max_accuracy = accuracy\n",
    "                        \n",
    "                    print(classification_report(test_labels['label'], predictii))\n",
    "                    print(\"accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\nBEST SCORE\")\n",
    "print(best_tfidf)\n",
    "print(best_model)\n",
    "# print(classification_report(test_labels['label'], predictii))\n",
    "print(\"accuracy:\", max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefabf7012fbb6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:16:28.134111100Z",
     "start_time": "2024-01-02T22:13:22.451333Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1,2))\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(preprocessed_data_train['text']) \n",
    "test_tfidf = tfidf_vectorizer.transform(preprocessed_data_test['text']) \n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(train_tfidf, train_labels['label'])\n",
    "predictii = model.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27dd131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.80      0.72      2250\n",
      "     neutral       0.53      0.23      0.32      1500\n",
      "    positive       0.72      0.83      0.77      2250\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.63      0.62      0.61      6000\n",
      "weighted avg       0.65      0.67      0.64      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels['label'], predictii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88167700689cc17a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T22:16:53.644177700Z",
     "start_time": "2024-01-02T22:16:52.943196300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels['label'], predictii)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples', xticklabels = ['negative', 'neutral', 'positive'], yticklabels = ['negative', 'neutral', 'positive'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e122ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
